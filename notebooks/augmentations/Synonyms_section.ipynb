{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d24a119",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "941b1490",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 24666 # 23 42 24666\n",
    "init_df_path = Path(f\"../../data/classification/baseline/train_{seed}.csv\")\n",
    "output_folder = Path(f\"../../data/classification/synonyms\")\n",
    "text_column = \"Текст\"\n",
    "label_column = \"Тональность\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0b5861",
   "metadata": {},
   "source": [
    "# Base Synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b393b614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install git+https://github.com/ahmados/rusynonyms.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "66c8dae6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install spacy==3.1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "47ca1b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.ru import Russian\n",
    "\n",
    "import random\n",
    "from ru_synonyms import AntonymsGraph, SynonymsGraph\n",
    "\n",
    "nlp = Russian()\n",
    "# Initialize both synonyms and antonyms graph\n",
    "sg = SynonymsGraph()\n",
    "ag = AntonymsGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "884319ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_random_word(text):\n",
    "    tokenized = [token.text for token in nlp(text) if not token.is_punct]\n",
    "    \n",
    "    if len(tokenized) == 0:\n",
    "        return \"No luck\"\n",
    "    \n",
    "    random_word = random.choice(range(len(tokenized)))\n",
    "    if sg.is_in_dictionary(tokenized[random_word]):\n",
    "        synonyms = list(sg.get_list(tokenized[random_word]))\n",
    "        if len(synonyms):\n",
    "            random_word_syn = random.choice(synonyms)\n",
    "            tokenized[random_word] = random_word_syn\n",
    "            return ' '.join(tokenized)\n",
    "    else:\n",
    "        list_copy = [i for i in range(len(tokenized))]      \n",
    "        random.shuffle(list_copy)\n",
    "        for token in list_copy:\n",
    "            if sg.is_in_dictionary(tokenized[token]):\n",
    "                synonyms = list(sg.get_list(tokenized[token]))\n",
    "                if len(synonyms):\n",
    "                    word_syn = random.choice(synonyms)\n",
    "                    tokenized[token] = word_syn\n",
    "                    return ' '.join(tokenized)\n",
    "    return \"No luck\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "841a349d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11668, 4)\n",
      "Failed 1725 times.\n",
      "21611 21611\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(init_df_path)\n",
    "print(df.shape)\n",
    "\n",
    "df_done = pd.DataFrame()\n",
    "\n",
    "texts, labels = [], []\n",
    "texts.extend(df[text_column].tolist())\n",
    "labels.extend(df[label_column].tolist())\n",
    "\n",
    "fails = 0\n",
    "for i, raw in df.iterrows():\n",
    "    \n",
    "    text, label = raw[text_column], raw[label_column]\n",
    "    new_text = change_random_word(text)\n",
    "    \n",
    "    if new_text == \"No luck\":\n",
    "        fails += 1\n",
    "        continue\n",
    "        \n",
    "    texts.append(new_text)\n",
    "    labels.append(label)\n",
    "    \n",
    "print(f\"Failed {fails} times.\")\n",
    "print(len(texts), len(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f15d98",
   "metadata": {},
   "source": [
    "# W2V Synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f766413c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget http://vectors.nlpl.eu/repository/20/185.zip\n",
    "# !unzip -d 180/ 185.zip\n",
    "# !wget https://raw.githubusercontent.com/akutuzov/universal-pos-tags/4653e8a9154e93fe2f417c7fdb7a357b7d6ce333/ru-rnc.map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "03aca34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {}\n",
    "\n",
    "for line in open('ru-rnc.map'):\n",
    "    ms, ud = line.strip('\\n').split()\n",
    "    mapping[ms] = ud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "85917011",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import gensim\n",
    "from pymystem3 import Mystem\n",
    "from thefuzz import fuzz\n",
    "\n",
    "m = Mystem()\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('180/model.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c4dc6132",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_mystem_wo_filter(text):\n",
    "    tokens = []\n",
    "    norm_words = m.analyze(text)\n",
    "    \n",
    "    for norm_word in norm_words:\n",
    "        \n",
    "        if 'analysis' not in norm_word and 'text' in norm_word:\n",
    "            lemma = norm_word[\"text\"]\n",
    "            if lemma not in [' ', '\\n']:\n",
    "                pos = 'NUMPUNCT'\n",
    "                tokens.append(lemma+'_'+pos)\n",
    "            \n",
    "        elif not len(norm_word['analysis']):\n",
    "            lemma = norm_word['text']\n",
    "            pos = 'UNKN'\n",
    "            tokens.append(lemma+'_'+pos)\n",
    "        else:\n",
    "            for w in norm_word[\"analysis\"]:\n",
    "                if \"lex\" in w:\n",
    "                    lemma = w[\"lex\"].lower().strip()\n",
    "                    pos = w[\"gr\"].split(',')[0]\n",
    "                    pos = pos.split('=')[0].strip()\n",
    "                    pos = mapping[pos]\n",
    "                    tokens.append(lemma+'_'+pos)\n",
    "                else:\n",
    "                    lemma = w[\"text\"]\n",
    "                    pos = 'UNKN'\n",
    "                    tokens.append(lemma+'_'+pos)\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "10844b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_random_word_w2v(text):\n",
    "    \n",
    "    tokenized_normalized = normalize_mystem_wo_filter(text)\n",
    "    num = random.choice(range(len(tokenized_normalized)))\n",
    "    list_copy = [i for i in range(len(tokenized_normalized)) if '_NUMPUNCT' not in tokenized_normalized[i]]      \n",
    "    random.shuffle(list_copy)\n",
    "\n",
    "    i = 0\n",
    "    for token in list_copy:\n",
    "\n",
    "        if i != num:\n",
    "\n",
    "            if tokenized_normalized[token] in model.key_to_index:\n",
    "                synonyms = model.most_similar(tokenized_normalized[token])\n",
    "                synonyms = [syn[0] for syn in synonyms \\\n",
    "                            if fuzz.token_sort_ratio(syn[0], tokenized_normalized[token]) < 100]\n",
    "\n",
    "                if len(synonyms):\n",
    "                    word_syn = random.choice(synonyms)                                \n",
    "                    tokenized_normalized[token] = word_syn\n",
    "                    tokenized_normalized = [re.sub(\"_.+\", \"\", w) for w in tokenized_normalized]\n",
    "                    i +=1\n",
    "        if i > 0:            \n",
    "            return \" \".join(tokenized_normalized)\n",
    "    return \"No luck\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "09e3e39a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed 2669 times.\n",
      "30610 30610\n"
     ]
    }
   ],
   "source": [
    "fails = 0\n",
    "for i, raw in df.iterrows():\n",
    "    \n",
    "    text, label = raw[text_column], raw[label_column]\n",
    "    new_text = change_random_word_w2v(text)\n",
    "    \n",
    "    if new_text == \"No luck\":\n",
    "        fails += 1\n",
    "        continue\n",
    "        \n",
    "    texts.append(new_text)\n",
    "    labels.append(label)\n",
    "    \n",
    "print(f\"Failed {fails} times.\")\n",
    "print(len(texts), len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f86862b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30610, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Текст</th>\n",
       "      <th>Тональность</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30600</th>\n",
       "      <td>все -всегд оперативно и качественно</td>\n",
       "      <td>Положительный</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30601</th>\n",
       "      <td>нужно окно помыть .</td>\n",
       "      <td>Предложение</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30602</th>\n",
       "      <td>улучшать качество расчистка .</td>\n",
       "      <td>Предложение</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30603</th>\n",
       "      <td>пол у мы страшный ,  скоро быть запинаться .</td>\n",
       "      <td>Отрицательный</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30604</th>\n",
       "      <td>вообще не организовать данный процесс  \\n</td>\n",
       "      <td>Отрицательный</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30605</th>\n",
       "      <td>спасибо ,  что предоставлять троллейбус  \\n</td>\n",
       "      <td>Положительный</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30606</th>\n",
       "      <td>в офис долинск ,  ужасный работа клиринговый к...</td>\n",
       "      <td>Отрицательный</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30607</th>\n",
       "      <td>сервис удобный ,  но здание необходимый всесто...</td>\n",
       "      <td>Положительный</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30608</th>\n",
       "      <td>долго ждать машина возвращаться от клиентура ....</td>\n",
       "      <td>Отрицательный</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30609</th>\n",
       "      <td>все сделать весьма хорошо</td>\n",
       "      <td>Положительный</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Текст    Тональность\n",
       "30600                все -всегд оперативно и качественно  Положительный\n",
       "30601                                нужно окно помыть .    Предложение\n",
       "30602                      улучшать качество расчистка .    Предложение\n",
       "30603       пол у мы страшный ,  скоро быть запинаться .  Отрицательный\n",
       "30604          вообще не организовать данный процесс  \\n  Отрицательный\n",
       "30605        спасибо ,  что предоставлять троллейбус  \\n  Положительный\n",
       "30606  в офис долинск ,  ужасный работа клиринговый к...  Отрицательный\n",
       "30607  сервис удобный ,  но здание необходимый всесто...  Положительный\n",
       "30608  долго ждать машина возвращаться от клиентура ....  Отрицательный\n",
       "30609                          все сделать весьма хорошо  Положительный"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_done[text_column] = texts\n",
    "df_done[label_column] = labels\n",
    "\n",
    "print(df_done.shape)\n",
    "df_done.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4f9d2326",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_done.to_csv(output_folder / f\"train_{seed}.csv\", index=False, encoding=\"utf-8\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diploma",
   "language": "python",
   "name": "diploma"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
